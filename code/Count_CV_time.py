# -*- coding: utf-8 -*-
import matplotlib.pyplot as plt
from os import listdir
from os.path import isfile, join

from sklearn.metrics import log_loss, confusion_matrix
from sklearn.model_selection import cross_val_score, KFold
from sklearn.preprocessing import scale, MinMaxScaler
from sklearn.linear_model import SGDClassifier
from sklearn.externals import joblib
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
from collections import Counter
from sklearn import tree
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.naive_bayes import BernoulliNB

import numpy as np
import os
import pickle
import re
import time

##################################################################################################################

def hasNumbers(inputString):
    return any(char.isdigit() for char in inputString)

##################################################################################################################

#### Load training ####
Y = pickle.load(open("BMsave/Y_data_asm", "r+b"))
nb_sample = len(Y)

s_word_asm = pickle.load(open("BMsave/set_word_asm", "r+b"))
X_asm = pickle.load(open("BMsave/X_data_asm", "r+b"))
idataVSize = pickle.load(open('BMsave/idataVSize', 'r+b'))
dllset = pickle.load(open('BMsave/dllset', 'r+b'))
dllcollect = pickle.load(open('BMsave/dllcollect', 'r+b'))


dict_s = dict(zip(s_word_asm, range(len(s_word_asm))))
outfile1 = open('BMsave\dict_s_asm', 'w+b')
pickle.dump(dict_s, outfile1)
outfile1.close()


dict_dll = dict(zip(dllset, range(len(dllset))))
outfile1 = open('BMsave\dict_dll', 'w+b')
pickle.dump(dict_dll, outfile1)
outfile1.close()


data_asm = np.zeros((nb_sample , len(s_word_asm) + len(dllset) + len(idataVSize[0]) ))

for i, cnt in enumerate(X_asm):

    if cnt!=0:
        for el in cnt:
            data_asm[i][dict_s[el]] = cnt[el]

    if dllcollect[i]!=[]:
        for each in dllcollect[i]:
            if each in dict_dll:
                data_asm[i][len(s_word_asm) + dict_dll[each]] = 1

    for j in range(len(idataVSize[0])):
        data_asm[i][len(s_word_asm) + len(dllset) + j] = idataVSize[i][j] #idataVariable size


data_asm = np.log(data_asm + 1)

min_max_scaler = MinMaxScaler()
data_asm = min_max_scaler.fit_transform(data_asm)


def run_cv(X, y, clf):
    # Construct a kfolds object
    split = 10
    kf = KFold(n_splits=split, shuffle=True)
    y_pred = np.zeros(len(y))

    total_training_time = 0
    total_testing_time = 0

    # Iterate through folds
    for train_index, test_index in kf.split(X):
        X_train, X_test = X[train_index], X[test_index]
        y_train = y[train_index]

        start = time.clock()  # 计算时间
        clf.fit(X_train, y_train)
        end = time.clock()  # 计算时间
        #print('training time:', end - start)
        total_training_time = total_training_time + end - start

        start = time.clock()  # 计算时间
        y_pred[test_index] = clf.predict(X_test)
        end = time.clock()  # 计算时间
        #print('testing time:', end - start)
        total_testing_time = total_testing_time + end - start

    average_training_time = total_training_time/split
    average_testing_time = total_testing_time/split

    print('training time:', average_training_time)
    print('testing time:', average_testing_time)

    return y_pred


#### See potential score on CV ####
#clf = SGDClassifier(loss="log", max_iter=100, shuffle=True, n_jobs=2)
#clf = RandomForestClassifier(n_estimators=10, criterion='gini')
#clf = tree.DecisionTreeClassifier(criterion='entropy')
#clf = GaussianNB()
#clf = KNeighborsClassifier(n_neighbors=3)
#clf = MultinomialNB()
#clf = SVC(kernel='sigmoid')
#clf = SVC(kernel="rbf", gamma=0.7)

print("----------------------------------------------------------")

####################################################################################
print("RandomForestClassifier(n_estimators=10, criterion='gini')")
clf = RandomForestClassifier(n_estimators=10, criterion='gini')
pred = run_cv(data_asm, Y, clf)
print('accuracy = ',end='')
print(accuracy_score(Y, pred))
print("----------------------------------------------------------")

####################################################################################
print("RandomForestClassifier(n_estimators=10, criterion='entropy')")
clf = RandomForestClassifier(n_estimators=10, criterion='entropy')
pred = run_cv(data_asm, Y, clf)
print('accuracy = ',end='')
print(accuracy_score(Y, pred))
print("----------------------------------------------------------")


####################################################################################
print("tree.DecisionTreeClassifier(criterion='gini')")
clf = tree.DecisionTreeClassifier(criterion='gini')
pred = run_cv(data_asm, Y, clf)
print('accuracy = ',end='')
print(accuracy_score(Y, pred))
print("----------------------------------------------------------")

####################################################################################
print("tree.DecisionTreeClassifier(criterion='entropy')")
clf = tree.DecisionTreeClassifier(criterion='entropy')
pred = run_cv(data_asm, Y, clf)
print('accuracy = ',end='')
print(accuracy_score(Y, pred))
print("----------------------------------------------------------")

####################################################################################
print("GaussianNB()")
clf = GaussianNB()
pred = run_cv(data_asm, Y, clf)
print('accuracy = ',end='')
print(accuracy_score(Y, pred))
print("----------------------------------------------------------")

####################################################################################
print("MultinomialNB()")
clf = MultinomialNB()
pred = run_cv(data_asm, Y, clf)
print('accuracy = ',end='')
print(accuracy_score(Y, pred))
print("----------------------------------------------------------")

####################################################################################
print("BernoulliNB()")
clf = BernoulliNB()
pred = run_cv(data_asm, Y, clf)
print('accuracy = ',end='')
print(accuracy_score(Y, pred))
print("----------------------------------------------------------")

####################################################################################
print("SVC(kernel='linear')")
clf = SVC(kernel='linear')
pred = run_cv(data_asm, Y, clf)
print('accuracy = ',end='')
print(accuracy_score(Y, pred))
print("----------------------------------------------------------")

####################################################################################
print('SVC(kernel="rbf", gamma=0.7)')
clf = SVC(kernel="rbf", gamma=0.7)
pred = run_cv(data_asm, Y, clf)
print('accuracy = ',end='')
print(accuracy_score(Y, pred))
print("----------------------------------------------------------")

####################################################################################
print("SVC(kernel='sigmoid')")
clf = SVC(kernel='sigmoid')
pred = run_cv(data_asm, Y, clf)
print('accuracy = ',end='')
print(accuracy_score(Y, pred))
print("----------------------------------------------------------")

####################################################################################
print('SGDClassifier(loss="log", max_iter=100, shuffle=True, n_jobs=2)')
clf = SGDClassifier(loss="log", max_iter=100, shuffle=True, n_jobs=2)
pred = run_cv(data_asm, Y, clf)
print('accuracy = ',end='')
print(accuracy_score(Y, pred))
print("----------------------------------------------------------")

####################################################################################
print('KNeighborsClassifier(n_neighbors=1)')
clf = KNeighborsClassifier(n_neighbors=1)
pred = run_cv(data_asm, Y, clf)
print('accuracy = ',end='')
print(accuracy_score(Y, pred))
print("----------------------------------------------------------")

####################################################################################
print('KNeighborsClassifier(n_neighbors=3)')
clf = KNeighborsClassifier(n_neighbors=3)
pred = run_cv(data_asm, Y, clf)
print('accuracy = ',end='')
print(accuracy_score(Y, pred))
print("----------------------------------------------------------")

####################################################################################
print('KNeighborsClassifier(n_neighbors=5)')
clf = KNeighborsClassifier(n_neighbors=5)
pred = run_cv(data_asm, Y, clf)
print('accuracy = ',end='')
print(accuracy_score(Y, pred))
print("----------------------------------------------------------")

####################################################################################
print('KNeighborsClassifier(n_neighbors=7)')
clf = KNeighborsClassifier(n_neighbors=7)
pred = run_cv(data_asm, Y, clf)
print('accuracy = ',end='')
print(accuracy_score(Y, pred))
print("----------------------------------------------------------")
